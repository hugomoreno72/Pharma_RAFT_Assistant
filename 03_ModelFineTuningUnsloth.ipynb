{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install transformers datasets accelerate peft trl bitsandbytes\n",
        "!pip install unsloth"
      ],
      "metadata": {
        "id": "F55hspqB1TX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tbZjt6PND-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8039253-c750-4363-b5f4-b202241e2c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ε Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "Ε Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from trl import SFTTrainer, SFTConfig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model and tokenizer with 4-bit quantization for memory efficiency\n",
        "max_seq_length = 2048\n",
        "dtype = None # Auto-detection\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/gemma-3-4b-it\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    load_in_8bit = False\n",
        ")"
      ],
      "metadata": {
        "id": "5QjemTgANfv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Low-Rank Adaptation (LoRA) to reduce the number of trainable parameters\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    r = 8,\n",
        "    lora_alpha = 8,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    random_state = 3407\n",
        ")"
      ],
      "metadata": {
        "id": "nIprNrLd1vVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"json\", data_files=\"pharmacy_raft_dataset.jsonl\", split=\"train\")"
      ],
      "metadata": {
        "id": "TmCscTfp2OWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import standardize_data_formats\n",
        "dataset = standardize_data_formats(dataset)"
      ],
      "metadata": {
        "id": "vAOLTEuS2COX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"gemma-3\",\n",
        ")"
      ],
      "metadata": {
        "id": "HSadeInMBltu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Format the RAFT dataset using a chat template for the trainer\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    contexts     = examples[\"context\"]\n",
        "    outputs      = examples[\"answer\"]\n",
        "    texts = []\n",
        "    for instruction, context, output in zip(instructions, contexts, outputs):\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {instruction}\"},\n",
        "            {\"role\": \"model\", \"content\": output},\n",
        "        ]\n",
        "        text = tokenizer.apply_chat_template(messages, tokenize = False, add_generation_prompt = False)\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True)"
      ],
      "metadata": {
        "id": "Ngi2B3fUNqjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the SFTTrainer with optimized hyperparameters for the 8B model\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    max_seq_length = max_seq_length,\n",
        "    args = SFTConfig(\n",
        "        dataset_text_field = \"text\",\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 30,\n",
        "        learning_rate = 2e-4,\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        report_to = \"none\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "MNknOnmZN-Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import train_on_responses_only\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part = \"<start_of_turn>user\\n\",\n",
        "    response_part = \"<start_of_turn>model\\n\",\n",
        ")"
      ],
      "metadata": {
        "id": "0G35eGsCGu55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ],
      "metadata": {
        "id": "WsEXIQm7y9Xb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a80924-20d8-40fb-b858-1f3397f9305d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "5.59 GB of memory reserved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "id": "fykC_lzsy-5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ],
      "metadata": {
        "id": "596iJgfjzctB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54009dbd-8ea2-485f-e08e-7140adfa2348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383.5385 seconds used for training.\n",
            "6.39 minutes used for training.\n",
            "Peak reserved memory = 6.883 GB.\n",
            "Peak reserved memory for training = 1.293 GB.\n",
            "Peak reserved memory % of max memory = 46.693 %.\n",
            "Peak reserved memory for training % of max memory = 8.771 %.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save_pretrained_gguf(\"model_gguf\", tokenizer, quantization_method = \"q4_k_m\")"
      ],
      "metadata": {
        "id": "HaW05VFwgcB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Define a test question\n",
        "instruction = \"Explain the mechanism of action of Warfarin and its main interactions.\"\n",
        "context = \"Warfarin inhibits vitamin K epoxide reductase. It interacts with cytochrome P450.\""
      ],
      "metadata": {
        "id": "S5VZQsU9fuDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {instruction}\"},\n",
        "]"
      ],
      "metadata": {
        "id": "jjScnbKYBk1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=True,\n",
        "    tokenize=False,\n",
        ")\n",
        "\n",
        "print(\"Generated prompt:\")\n",
        "print(prompt)\n",
        "print(type(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VUvi1JdFpqP",
        "outputId": "e4c33f64-28c1-4e7e-9dad-950db40045d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt generado:\n",
            "<bos><start_of_turn>user\n",
            "Contexto: La warfarina inhibe la ep贸xido reductasa de la vitamina K. Interacciona con el citocromo P450.\n",
            "\n",
            "Pregunta: Explica el mecanismo de acci贸n de la Warfarina y sus principales interacciones.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "    text=prompt,\n",
        "    return_tensors=\"pt\",\n",
        "    padding=True,\n",
        ").to(\"cuda\")\n",
        "\n",
        "print(f\"Shape: {inputs['input_ids'].shape}\")\n",
        "print(f\"Device: {inputs['input_ids'].device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHlr8vNoFxXl",
        "outputId": "aad6e6e7-807b-4066-987a-f4614e413bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: torch.Size([1, 64])\n",
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Generation\n",
        "outputs = model.generate(**inputs, max_new_tokens = 512, use_cache = True)\n",
        "response = tokenizer.tokenizer.batch_decode(outputs)\n",
        "\n",
        "print(\"--- ASSISTANT麓S ANSWER ---\")\n",
        "print(response[0].split(\"<start_of_turn>model\\n\")[-1])"
      ],
      "metadata": {
        "id": "2RC9cih3gRPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd22a08a-98be-4f2b-ed7e-5689ea98ed7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- RESPUESTA DEL ASISTENTE ---\n",
            "Para explicar el mecanismo de acci贸n de la warfarina y sus interacciones, es crucial comprender su forma de inhibir la vitamina K y su interacci贸n con el citocromo P450, y de esta forma, c贸mo afecta la producci贸n de factores de coagulaci贸n de la sangre.\n",
            "\n",
            "Mecanismo de Acci贸n:\n",
            "\n",
            "La warfarina es un f谩rmaco antiagregante plaquetario que act煤a principalmente inhibiendo la vitamina K ep贸xido reductasa, una enzima crucial en el metabolismo de la vitamina K. Los factores de coagulaci贸n de la sangre, como la II, VII, IX y X, se derivan de la vitamina K. La vitamina K ep贸xido reductasa es esencial para activar estos factores, y es necesario para su carboxilaci贸n, una reacci贸n que los hace funcionales como cofactores de coagulaci贸n. Al inhibir esta enzima, la warfarina bloquea la carboxilaci贸n de estos factores, lo que conduce a la producci贸n de factores de coagulaci贸n inactivos. Esto inhibe la cascada de coagulaci贸n, previniendo la formaci贸n de co谩gulos sangu铆neos.\n",
            "\n",
            "Interacciones:\n",
            "\n",
            "La warfarina tiene una variedad de interacciones con otros f谩rmacos, alimentos y otros compuestos que pueden afectar su eficacia o aumentar el riesgo de sangrado. Algunas de las interacciones m谩s importantes incluyen:\n",
            "\n",
            "1. Sustancias que afectan el metabolismo de la warfarina:\n",
            "   - Antif煤ngicos de azole (como itraconazol y voriconazol) son inhibidores del citocromo P450 que pueden aumentar los niveles de warfarina, aumentando el riesgo de hemorragia.\n",
            "   - Antihistam铆nicos de primera generaci贸n (como difenhidramina y clorfeniramina) tambi茅n son inhibidores del citocromo P450 que pueden aumentar los niveles de warfarina, similar a los antif煤ngicos de azole.\n",
            "   - Otros inhibidores del citocromo P450, como algunos antidepresivos, estatinas y antibi贸ticos, pueden afectar los niveles de warfarina, por lo que el seguimiento cuidadoso es esencial.\n",
            "\n",
            "2. Sustancias que aumentan el efecto de la warfarina:\n",
            "   - Algunos antibi贸ticos, como las fluoroquinolonas, pueden disminuir los niveles de vitamina K, lo que puede provocar un efecto de la warfarina m谩s potente.\n",
            "   - El uso de suplementos de vitamina K o la incorporaci贸n de\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Fine-Tuned LoRA adapters locally\n",
        "nombre_carpeta = \"lora_pharma\"\n",
        "model.save_pretrained(nombre_carpeta)\n",
        "tokenizer.save_pretrained(nombre_carpeta)\n",
        "\n",
        "# 2.Zip the folder\n",
        "import shutil\n",
        "shutil.make_archive(nombre_carpeta, 'zip', nombre_carpeta)\n",
        "\n",
        "# Download the zipped folder\n",
        "from google.colab import files\n",
        "files.download(f\"{nombre_carpeta}.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "UIYaTTNDJWmv",
        "outputId": "ec9ac8e1-c956-40dc-819c-13542e7861cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6b4819c9-e30d-4d20-a3e6-1415db44854f\", \"lora_pharma.zip\", 64525034)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}